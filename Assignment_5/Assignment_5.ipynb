{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECE-6524 / CS-6524 Deep Learning\n",
    "# Assignment 5 (110 pts)\n",
    "\n",
    "In this assignment, **you will implement the following:**\n",
    "1. GAN / LSGAN loss functions and training code for MNIST dataset.\n",
    "2. Train GAN / LSGAN on CelebA dataset with DCGAN architecture.\n",
    "\n",
    "**<span style=\"color:red\">Again, it may take hours to train on CelebA. So start early.</span>** (We don't want you to work during holidays)\n",
    "\n",
    "## Submission guideline for the coding part (Jupyter Notebook)\n",
    "\n",
    "1. Click the Save button at the top of the Jupyter Notebook\n",
    "2. Please make sure to have entered your Virginia Tech PID below\n",
    "3. Once you've completed everything (make sure output for all cells are visible), select File -> Download as -> PDF via LaTeX\n",
    "4. Look at the PDF file and make sure all your solutions are displayed correctly there \n",
    "7. Zip this notebook (Please don't include the data). Name it as Assignment_3_Code_[YOUR PID NUMBER].zip\n",
    "8. Name your PDF file as Assignment_4_NB_[YOUR PID NUMBER].pdf\n",
    "9. **<span style=\"color:blue\"> Submit your zipped file and the PDF SEPARATELY**</span>\n",
    "\n",
    "Note: if facing issues with step 3 refer: https://pypi.org/project/notebook-as-pdf/\n",
    "\n",
    "## Submission guideline for the coding part (Google Colab)\n",
    "\n",
    "1. Click the Save button at the top of the Notebook\n",
    "2. Please make sure to have entered your Virginia Tech PID below\n",
    "3. Follow last two cells in this notebook for guidelines to download pdf file of this notebook\n",
    "4. Look at the PDF file and make sure all your solutions are displayed correctly there \n",
    "5. Zip this notebook (Please don't include the data). Name it as Assignment_2_Code_[YOUR PID NUMBER].zip\n",
    "6. Name your PDF file as Assignment_4_NB_[YOUR PID NUMBER].pdf\n",
    "7. **<span style=\"color:blue\"> Submit your zipped file and the PDF SEPARATELY**</span>\n",
    "\n",
    "**While you are encouraged to discuss with your peers, <span style=\"color:blue\">all work submitted is expected to be your own.</span> <span style=\"color:red\">If you use any information from other resources (e.g. online materials), you are required to cite it below you VT PID. Any violation will result in a 0 mark for the assignment.</span>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Colab Setup: \n",
    "- Below are some basic steps for colab setup. \n",
    "- Make changes based on requirements.\n",
    "- Comment out in case of ARC or your local device with powerful GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# modify \"path_to_homework\", path of folder in drive, where you uploaded your homework files\n",
    "path_to_homework = \"/content/drive/My Drive/DL/Assignment_5/\"\n",
    "sys.path.append(path_to_homework)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1. Generative Adversarial Networks on MNIST Dataset [54 pts]\n",
    "\n",
    "In this section, you will need to:\n",
    "1. Implement two different types of loss functions (GAN / LSGAN) for generative adversarial networks. \n",
    "2. Build the Discriminator and Generator.\n",
    "3. Implement training codes for your GAN models.\n",
    "3. Train your model on MNIST dataset and visualize the generated images.\n",
    "\n",
    "Now, let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images(images, color=False):\n",
    "    if color:\n",
    "        sqrtimg = int(np.ceil(np.sqrt(images.shape[2]*images.shape[3])))\n",
    "    else:\n",
    "        images = np.reshape(images, [images.shape[0], -1])  # images reshape to (batch_size, D)\n",
    "        sqrtimg = int(np.ceil(np.sqrt(images.shape[1])))\n",
    "    sqrtn = int(np.ceil(np.sqrt(images.shape[0])))\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(sqrtn, sqrtn))\n",
    "    gs = gridspec.GridSpec(sqrtn, sqrtn)\n",
    "    gs.update(wspace=0.05, hspace=0.05)\n",
    "\n",
    "    for i, img in enumerate(images):\n",
    "        ax = plt.subplot(gs[i])\n",
    "        plt.axis('off')\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels([])\n",
    "        ax.set_aspect('equal')\n",
    "        if color:\n",
    "            plt.imshow(np.swapaxes(np.swapaxes(img, 0, 1), 1, 2))\n",
    "        else:\n",
    "            plt.imshow(img.reshape([sqrtimg,sqrtimg]))\n",
    "    return \n",
    "\n",
    "def preprocess_img(x):\n",
    "    return 2 * x - 1.0\n",
    "\n",
    "def deprocess_img(x):\n",
    "    return (x + 1.0) / 2.0\n",
    "\n",
    "def rel_error(x,y):\n",
    "    return np.max(np.abs(x - y) / (np.maximum(1e-8, np.abs(x) + np.abs(y))))\n",
    "\n",
    "def sample_noise(batch_size, dim):\n",
    "    \"\"\"\n",
    "    Generate a PyTorch Tensor of uniform random noise.\n",
    "\n",
    "    Input:\n",
    "    - batch_size: Integer giving the batch size of noise to generate.\n",
    "    - dim: Integer giving the dimension of noise to generate.\n",
    "    \n",
    "    Output:\n",
    "    - A PyTorch Tensor of shape (batch_size, dim) containing uniform\n",
    "      random noise in the range (-1, 1).\n",
    "    \"\"\"\n",
    "    to_return = torch.randn((batch_size, dim))\n",
    "    return to_return/torch.max(to_return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set your device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1.1. Vanilla GAN loss functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QOVWxdbK-nuI"
   },
   "source": [
    "### Section 1.1.1 GAN Loss [10 pts]\n",
    "We start from implementing the vanilla GAN loss from the [original GAN paper](https://arxiv.org/pdf/1406.2661.pdf). Specifically, you need to complete the `generator_loss` and `discriminator_loss` in the cell below.\n",
    "\n",
    "Recalled from the class, the generator loss is written as:\n",
    "$$\\ell_G  =  -\\mathbb{E}_{z \\sim p(z)}\\left[\\log D(G(z))\\right]$$\n",
    "and the discriminator loss is:\n",
    "$$ \\ell_D = -\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\log D(x)\\right] - \\mathbb{E}_{z \\sim p(z)}\\left[\\log \\left(1-D(G(z))\\right)\\right]$$\n",
    "Note that these equations could be silghtly different from what we have seen before. This is because that in Pytorch, our optimize will be *minimizing* the loss functions. As a result, we negate the formulas to match pytorch's behavior.\n",
    "\n",
    "**HINTS**: You should use the `torch.nn.functional.binary_cross_entropy_with_logits` function to compute the binary cross entropy loss since it is more numerically stable than using a softmax followed by BCE loss. The BCE loss is needed to compute the log probability of the true label given the logits output from the discriminator. Given a score $s\\in\\mathbb{R}$ and a label $y\\in\\{0, 1\\}$, the binary cross entropy loss is\n",
    "\n",
    "$$ bce(s, y) = -y * \\log(s) - (1 - y) * \\log(1 - s) $$\n",
    "\n",
    "\n",
    "Instead of computing the expectation of $\\log D(G(z))$, $\\log D(x)$ and $\\log \\left(1-D(G(z))\\right)$, we will be averaging over elements of the minibatch, so make sure to combine the loss by averaging instead of summing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_loss(logits_real, logits_fake):\n",
    "    \"\"\"\n",
    "    Computes the discriminator loss.\n",
    " \n",
    "    You should use the stable torch.nn.functional.binary_cross_entropy_with_logits\n",
    "    loss rather than using a separate softmax function followed by the binary cross\n",
    "    entropy loss.\n",
    " \n",
    "    Inputs:\n",
    "    - logits_real: PyTorch Tensor of shape (N,) giving scores for the real data.\n",
    "    - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
    " \n",
    "    Returns:\n",
    "    - loss: PyTorch Tensor containing (scalar) the loss for the discriminator.\n",
    "    \"\"\"\n",
    " \n",
    "    loss = None\n",
    "    \n",
    "    ####################################\n",
    "    #          YOUR CODE HERE          #\n",
    "    ####################################\n",
    "\n",
    "    ##########       END      ##########\n",
    "    return loss\n",
    "\n",
    "def generator_loss(logits_fake):\n",
    "    \"\"\"\n",
    "    Computes the generator loss.\n",
    "\n",
    "    You should use the stable torch.nn.functional.binary_cross_entropy_with_logits\n",
    "    loss rather than using a separate softmax function followed by the binary cross\n",
    "    entropy loss.\n",
    "\n",
    "    Inputs:\n",
    "    - logits_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
    "    \n",
    "    Returns:\n",
    "    - loss: PyTorch Tensor containing the (scalar) loss for the generator.\n",
    "    \"\"\"\n",
    "\n",
    "    loss = None\n",
    " \n",
    "    ####################################\n",
    "    #          YOUR CODE HERE          #\n",
    "    ####################################\n",
    "    ##########       END      ##########\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.1.2 Build simple model [10 pts]\n",
    "\n",
    "Build your simple model using below layers:\n",
    "\n",
    "**Discriminator:**\n",
    "\n",
    "- Flatten input (flatten the C x H x W into a single vector per image)\n",
    "- linear (784, 256)\n",
    "- Leaky ReLU ()\n",
    "- Linear(256, 256)\n",
    "- Leaky ReLU()\n",
    "- Linear(256, 1)\n",
    "\n",
    "**Generator:**\n",
    "- Linear(noise_dim, 1024)\n",
    "- ReLU()\n",
    "- Linear(1024, 1024)\n",
    "- ReLU()\n",
    "- linear(1024, 784)\n",
    "- Tanh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 100\n",
    "\n",
    "def discriminator():\n",
    "    \"\"\"\n",
    "    Initialize and return a simple discriminator model.\n",
    "    \"\"\"\n",
    "    # Your code here:\n",
    "    return model\n",
    "\n",
    "def generator(noise_dim=NOISE_DIM):\n",
    "    \"\"\"\n",
    "    Initialize and return a simple generator model.\n",
    "    \"\"\"\n",
    "    # Your code here:\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.1.3 Training code [10 pts]\n",
    "You can't train a model without a proper training code. Implement the GAN training procedure here following the [original GAN paper](https://arxiv.org/pdf/1406.2661.pdf) and the course slides in the cell below. Note that this code would be reused in the subsequent section, so make sure that it is correctly implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    " \n",
    "def train(D, G, D_solver, G_solver, discriminator_loss, generator_loss, show_every=250, \n",
    "          ckpt_dir = path_to_homework + '/ckpts/Vanilla_gan_MINST/', cont_train=False,\n",
    "          batch_size=128, noise_size=100, num_epochs=10, train_loader=None, device=None):\n",
    "    \"\"\"\n",
    "    Train loop for GAN.\n",
    "\n",
    "    The loop will consist of two steps: a discriminator step and a generator step.\n",
    "\n",
    "    (1) In the discriminator step, you should zero gradients in the discriminator\n",
    "    and sample noise to generate a fake data batch using the generator. Flatten real images \n",
    "    to 784 (28 * 28). Calculate the discriminator output for real and fake data, \n",
    "    and use the output to compute discriminator loss. Call backward() on the loss \n",
    "    output and take an optimizer step for the discriminator.\n",
    "\n",
    "    (2) For the generator step, you should once again zero gradients in the generator\n",
    "    and sample noise to generate a fake data batch. Get the discriminator output\n",
    "    for the fake data batch and use this to compute the generator loss. Once again\n",
    "    call backward() on the loss and take an optimizer step.\n",
    "\n",
    "    You will need to reshape the fake image tensor outputted by the generator to\n",
    "    be dimensions (batch_size x input_channels x img_size x img_size).\n",
    "\n",
    "    Use the sample_noise function to sample random noise, and the discriminator_loss\n",
    "    and generator_loss functions for their respective loss computations\n",
    "\n",
    "    Inputs:\n",
    "    - D, G: PyTorch models for the discriminator and generator\n",
    "    - D_solver, G_solver: torch.optim Optimizers to use for training the\n",
    "      discriminator and generator.\n",
    "    - discriminator_loss, generator_loss: Functions to use for computing the generator and\n",
    "      discriminator loss, respectively.\n",
    "    - show_every: Show samples after every show_every iterations.\n",
    "    - batch_size: Batch size to use for training.\n",
    "    - noise_size: Dimension of the noise to use as input to the generator.\n",
    "    - num_epochs: Number of epochs over the training dataset to use for training.\n",
    "    - train_loader: image dataloader\n",
    "    - device: PyTorch device\n",
    "    \"\"\"\n",
    "    if os.path.exists(os.path.join(ckpt_dir, 'checkpoint.pth')) and cont_train:\n",
    "        ckpt = torch.load(os.path.join(ckpt_dir, 'checkpoint.pth'))\n",
    "        start_epoch = ckpt['epoch'] + 1\n",
    "        iter_count = ckpt['iter_count'] + 1\n",
    "        G.load_state_dict(ckpt['G'])\n",
    "        D.load_state_dict(ckpt['D'])\n",
    "        print('Start from a checkpoint: {}, epoch:{}, iter:{}'.format(os.path.join(ckpt_dir, 'checkpoint.pth'), \n",
    "                                                 str(start_epoch), str(iter_count)))\n",
    "    else:\n",
    "        start_epoch = 0\n",
    "        iter_count = 0\n",
    "        \n",
    "    for epoch in range(start_epoch, num_epochs):\n",
    "        print('EPOCH: ', (epoch+1))\n",
    "        for x, _ in train_loader:\n",
    "            _, input_channels, img_size, _ = x.shape\n",
    "\n",
    "            real_images = preprocess_img(x).to(device)  # normalize\n",
    "\n",
    "            # Store discriminator loss output, generator loss output, and fake image output\n",
    "            # in these variables for logging and visualization below\n",
    "            d_error = None\n",
    "            g_error = None\n",
    "            fake_images = None\n",
    "\n",
    "\n",
    "            ####################################\n",
    "            #        Discriminator step        #\n",
    "            #          YOUR CODE HERE          #\n",
    "            ####################################\n",
    "            \n",
    "            #########       END      ###########\n",
    " \n",
    "            ####################################\n",
    "            #          Generator step          #\n",
    "            #          YOUR CODE HERE          #\n",
    "            ####################################\n",
    "            \n",
    "            ##########       END      ##########\n",
    "            if (iter_count % show_every == 0):\n",
    "                print('Iter: {}, D: {:.4}, G:{:.4}'.format(iter_count,d_error.item(),g_error.item()))\n",
    "                disp_fake_images = deprocess_img(fake_images.data)  # denormalize\n",
    "                imgs_numpy = (disp_fake_images).cpu().numpy()\n",
    "                show_images(imgs_numpy[0:16], color=input_channels!=1)\n",
    "                plt.show()\n",
    "                print()\n",
    "            iter_count += 1\n",
    "            \n",
    "        # save checkpoints\n",
    "        os.makedirs(ckpt_dir, exist_ok=True)\n",
    "        print('Saving the model as a checkpoint...')\n",
    "        torch.save({'epoch': epoch, \n",
    "                    'iter_count': iter_count,\n",
    "                    'G': G.state_dict(), \n",
    "                    'D': D.state_dict()}, \n",
    "                   os.path.join(ckpt_dir, 'checkpoint.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MNIST is a simple dataset that contains one hand-written digit in each image. It is usually used for sanity check. So, let's test our loss functions and training code on it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "mnist = datasets.MNIST('./MNIST_data', train=True, download=True,\n",
    "                           transform=transforms.ToTensor())\n",
    "loader_train = DataLoader(mnist, batch_size=batch_size, drop_last=True)\n",
    "\n",
    "\n",
    "imgs = loader_train.__iter__().next()[0].view(batch_size, 784).numpy().squeeze()\n",
    "show_images(imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.1.4 Train your model [7 pts]\n",
    "\n",
    "- Call Discriminator and Generator for training.\n",
    "- Call optimizers for both discriminator and generator for training. (Use Adam with lr=1e-3, betas = (0.5, 0.999))\n",
    "- Call train function to train. \n",
    "- Train for 10 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training your GAN model, you should expect results that resemble the following if your loss function and training loop implementations are correct:\n",
    "\n",
    "<img src=\"files/gan_samples/mnist_gan.jpg\" width=300>\n",
    "Refer mnist.jpg from gan_samples folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add training code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RXfoe96P-nud"
   },
   "source": [
    "## Section 1.2 Least-square GAN Loss\n",
    "### Section 1.2.1 LSGAN Loss [10 pts]\n",
    "We'll now look at [Least Squares GAN](https://arxiv.org/abs/1611.04076), a newer, more stable alernative to the original GAN loss function. For this part, all we have to do is change the loss function and retrain the model. We'll implement equation (9) in the paper, with the generator loss:\n",
    "$$\\ell_G  =  \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[\\left(D(G(z))-1\\right)^2\\right]$$\n",
    "and the discriminator loss:\n",
    "$$ \\ell_D = \\frac{1}{2}\\mathbb{E}_{x \\sim p_\\text{data}}\\left[\\left(D(x)-1\\right)^2\\right] + \\frac{1}{2}\\mathbb{E}_{z \\sim p(z)}\\left[ \\left(D(G(z))\\right)^2\\right]$$\n",
    "Fill in the `ls_discriminator_loss` and `ls_generator_loss` in the cell below.\n",
    "\n",
    "**HINTS**: Instead of computing the expectation, we will be averaging over elements of the minibatch, so make sure to combine the loss by averaging instead of summing. When plugging in for $D(x)$ and $D(G(z))$ use the direct output from the discriminator (`scores_real` and `scores_fake`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ls_discriminator_loss(logits_real, logits_fake):\n",
    "    \"\"\"\n",
    "    Compute the Least-Squares GAN loss for the discriminator.\n",
    "\n",
    "    Inputs:\n",
    "    - scores_real: PyTorch Tensor of shape (N,) giving scores for the real data.\n",
    "    - scores_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
    " \n",
    "    Outputs:\n",
    "    - loss: A PyTorch Tensor containing the loss.\n",
    "    \"\"\"\n",
    " \n",
    "    loss = None\n",
    "    \n",
    "    ####################################\n",
    "    #          YOUR CODE HERE          #\n",
    "    ####################################\n",
    "\n",
    "    ##########       END      ##########\n",
    "    return loss\n",
    "\n",
    "def ls_generator_loss(logits_fake):\n",
    "    \"\"\"\n",
    "    Computes the Least-Squares GAN loss for the generator.\n",
    " \n",
    "    Inputs:\n",
    "    - scores_fake: PyTorch Tensor of shape (N,) giving scores for the fake data.\n",
    " \n",
    "    Outputs:\n",
    "    - loss: A PyTorch Tensor containing the loss.\n",
    "    \"\"\"\n",
    "\n",
    "    loss = None\n",
    " \n",
    "    ####################################\n",
    "    #          YOUR CODE HERE          #\n",
    "    ####################################\n",
    "    \n",
    "    ##########       END      ##########\n",
    "    return loss    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 1.2.2 Train model with LSGAN loss[7 pts]\n",
    "\n",
    "- Call Discriminator and Generator for training.\n",
    "- Call optimizers for both discriminator and generator for training. (Use Adam with lr=1e-3, betas = (0.5, 0.999))\n",
    "- Call train function to train. \n",
    "- Train for 10 epochs.\n",
    "\n",
    "Similarly, train your LSGAN on MNIST dataset. You should expect results that resemble the following if your loss function and training loop implementations are correct:\n",
    "\n",
    "<img src=\"files/gan_samples/mnist_ls.jpg\" width=300>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR TRAINING CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 2. Generative Adversarial Networks on CelebA Dataset [56 pts]\n",
    "\n",
    "In this section, you will need to:\n",
    "1. Implement DCGAN architecture\n",
    "2. Train it on CelebA dataset.\n",
    "\n",
    "We are done with the simple, not-so-challenging MNIST dataset. Now, you need to implement a specific model architecture called [DCGAN](https://arxiv.org/pdf/1511.06434.pdf), and train your model to generate human faces!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.1. GAN model architecture [20 pts]\n",
    "\n",
    "Implement your generator and discriminator for generating faces. We recommend the following architectures which are inspired by [DCGAN](https://arxiv.org/pdf/1511.06434.pdf):\n",
    "**Discriminator:**\n",
    "\n",
    "- convolutional layer with in_channels=3, out_channels=128, kernel=4, stride=2\n",
    "- convolutional layer with in_channels=128, out_channels=256, kernel=4, stride=2\n",
    "- batch norm\n",
    "- convolutional layer with in_channels=256, out_channels=512, kernel=4, stride=2\n",
    "- batch norm\n",
    "- convolutional layer with in_channels=512, out_channels=1024, kernel=4, stride=2\n",
    "- batch norm\n",
    "- convolutional layer with in_channels=1024, out_channels=1, kernel=4, stride=1\n",
    "\n",
    "Instead of Relu we use LeakyReLu throughout the discriminator (we use a negative slope value of 0.2). \n",
    "\n",
    "The output of your discriminator should be a single value score corresponding to each input sample. See `torch.nn.LeakyReLU`.\n",
    "\n",
    "\n",
    "**Generator:**\n",
    "\n",
    "**Note:** In the generator, you will need to use transposed convolution (sometimes known as fractionally-strided convolution or deconvolution). This function is implemented in pytorch as `torch.nn.ConvTranspose2d`.\n",
    "\n",
    "- transpose convolution with in_channels=NOISE_DIM, out_channels=1024, kernel=4, stride=1\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=1024, out_channels=512, kernel=4, stride=2\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=512, out_channels=256, kernel=4, stride=2\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=256, out_channels=128, kernel=4, stride=2\n",
    "- batch norm\n",
    "- transpose convolution with in_channels=128, out_channels=3, kernel=4, stride=2\n",
    "\n",
    "The output of the final layer of the generator network should have a `tanh` nonlinearity to output values between -1 and 1. The output should be a 3x64x64 tensor for each sample (equal dimensions to the images from the dataset).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR GENERATOR/DISCRIMINATOR HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_sgpDWlbM90t"
   },
   "source": [
    "### Section 2.2 Data loading: Celeb A Dataset\n",
    "\n",
    "The CelebA images we provide have been filtered to obtain only images with clear faces and have been cropped and downsampled to 128x128 resolution.\n",
    "\n",
    "Run download_celeba.sh to get dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "scale_size = 64  # We resize the images to 64x64 for training\n",
    "\n",
    "celeba_root = 'celeba_data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6IzyDdZM9bp"
   },
   "outputs": [],
   "source": [
    "celeba_train = ImageFolder(root=celeba_root, transform=transforms.Compose([\n",
    "  transforms.Resize(scale_size),\n",
    "  transforms.ToTensor(),\n",
    "]))\n",
    "\n",
    "# You can change the num_workers to speed up loading\n",
    "celeba_loader_train = DataLoader(celeba_train, batch_size=batch_size, drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 12368,
     "status": "ok",
     "timestamp": 1541578338354,
     "user": {
      "displayName": "Daniel McKee",
      "photoUrl": "",
      "userId": "05833574158187352909"
     },
     "user_tz": 360
    },
    "id": "uiThPjUSwc3P",
    "outputId": "ee3c69cf-e5f2-43c1-9fcc-46cdb650bec1",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "imgs = celeba_loader_train.__iter__().next()[0].numpy().squeeze()\n",
    "show_images(imgs, color=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.3 Train a Vanilla GAN on CelebA [13 pts]\n",
    "\n",
    "- Call discriminator and generator for training.\n",
    "- Call optimizers for both discriminator and generator for training. (Use Adam with betas = (0.5, 0.999))\n",
    "- Call train function to train. \n",
    "- Train for 30 epochs.\n",
    "\n",
    "Now, train your GAN model with vanilla GAN loss. If you models are implemented correctly, you should see something like this:\n",
    "<img src=\"files/gan_samples/celeba.jpg\" width=300>\n",
    "\n",
    "\n",
    "Now, train your model. **Observe the visualized result of your model, and describe what you see.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NOISE_DIM = 100\n",
    "NUM_EPOCHS = 30\n",
    "learning_rate = 0.0002"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1197,
     "status": "ok",
     "timestamp": 1541580362058,
     "user": {
      "displayName": "Daniel McKee",
      "photoUrl": "",
      "userId": "05833574158187352909"
     },
     "user_tz": 360
    },
    "id": "qbcFiz0pI1yF",
    "outputId": "4b19ba28-1983-4ba5-c76d-58e1b04ed031",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# original GAN\n",
    "# Add code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Section 2.4 Train a LSGAN on CelebA [13 pts]\n",
    "\n",
    "- Call discriminator and generator for training.\n",
    "- Call optimizers for both discriminator and generator for training. (Use Adam with betas = (0.5, 0.999))\n",
    "- Call train function to train. \n",
    "- Train for 30 epochs.\n",
    "\n",
    "Now, train your GAN model with LSGAN loss. **Observe the visualized result of your model, and describe what you see.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSGAN\n",
    "# Add code here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Section 2.6 Conclusion? [10 pts]\n",
    "You have successfully trained you GAN models. Hurray! Now, we want you to answer the following question in few sentences.\n",
    "1. Have you observed any difference between GAN and LSGAN (e.g. training, generation quality)?\n",
    "2. Did your GAN models generate you diverse faces? Or did it should give you similar stuff all the time?\n",
    "3. How can you quantitatively evaluate your GAN model? Is the metric(s) meaningful? Is there any drawback about this metric(s)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines for Downloading PDF in Google Colab\n",
    "- Run below cells only in Google Colab, Comment out in case of Jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Run below two lines (in google colab), installation steps to get .pdf of the notebook\n",
    "\n",
    "!apt-get install texlive texlive-xetex texlive-latex-extra pandoc\n",
    "!pip install pypandoc\n",
    "\n",
    "# After installation, comment above two lines and run again to remove installation comments from the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find path to your notebook file in drive and enter in below line\n",
    "\n",
    "!jupyter nbconvert --to PDF \"your_notebook_path_here/DL_Assignment_5.ipynb\"\n",
    "\n",
    "#Example: \"/content/drive/My Drive/DL_Fall_2020/Assignment_5/DL_Assignment_5.ipynb\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
